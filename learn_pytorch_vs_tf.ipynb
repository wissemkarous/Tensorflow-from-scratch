{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMwwJZD8XcqJjFfxtCHZcTv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wissemkarous/Tensorflow-from-scratch/blob/main/learn_pytorch_vs_tf.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim"
      ],
      "metadata": {
        "id": "BpsEYvkbzELJ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#import data :\n",
        "transforms=torchvision.transforms.Compose([torchvision.transforms.ToTensor()])\n",
        "train_dataset=torchvision.datasets.FashionMNIST(root='data',train=True,download=True,transform=transforms)\n",
        "test_dataset=torchvision.datasets.FashionMNIST(root='data',train=False,download=True,transform=transforms)\n",
        "# import data using tf\n",
        "fashion_mnist=tf.keras.datasets.fashion_mnist\n",
        "(train_images,train_labels),(test_images,test_labels)=fashion_mnist.load_data()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "40qCMFMnJdVM",
        "outputId": "c978e538-e207-4589-c164-9652ac454fd8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26421880/26421880 [00:00<00:00, 68011577.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/train-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29515/29515 [00:00<00:00, 2054073.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "100%|██████████| 4422102/4422102 [00:00<00:00, 21605184.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5148/5148 [00:00<00:00, 23832535.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "29515/29515 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26421880/26421880 [==============================] - 1s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "5148/5148 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4422102/4422102 [==============================] - 1s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#PyTorch - Loading the Data\n",
        "def imshowPytorch(img):\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                           batch_size=32,\n",
        "                                           shuffle=False)\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
        "                                           batch_size=32,\n",
        "                                           shuffle=False)\n",
        "\n",
        "data_iter = iter(train_loader)\n",
        "images, label = next(data_iter)\n",
        "imshowPytorch(torchvision.utils.make_grid(images[0]))\n",
        "print(label[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "7DJRZ0OeTsIy",
        "outputId": "9b856496-cf60-4d5a-e352-41bbf0916031"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(9)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# building the model\n",
        "modeltf = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv2D(input_shape=(28,28,1),filters=32,kernel_size=(3,3),activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size=(2,2),strides=2),\n",
        "    tf.keras.layers.Conv2D(filters=64,kernel_size=(3,3),activation='relu'),\n",
        "    tf.keras.layers.AveragePooling2D(pool_size=(2,2),strides=2),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(120,activation='relu'),\n",
        "    tf.keras.layers.Dense(84,activation='relu'),\n",
        "    tf.keras.layers.Dense(10,activation='softmax')\n",
        "])\n"
      ],
      "metadata": {
        "id": "5CWYZr5026ZX"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class modelpytorch(nn.Module):\n",
        "    def __init__(self, num_of_class):\n",
        "        super(modelpytorch, self).__init__()\n",
        "        self.cnn_model = nn.Sequential(\n",
        "            nn.Conv2d(1, 6, kernel_size=5, stride=1, padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.AvgPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(6, 16, kernel_size=5, stride=1, padding=0),\n",
        "            nn.ReLU(),\n",
        "            nn.AvgPool2d(kernel_size=2, stride=2))\n",
        "        self.fc_model = nn.Sequential(\n",
        "            nn.Linear(400,120),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(120,84),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "        self.classifier = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.cnn_model(x)\n",
        "        x = x.view(-1, 16*5*5)\n",
        "        x = self.fc_model(x)\n",
        "        x = self.classifier(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "8vmeNIiz3prN"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#PyTorch - Visualizing the Model\n",
        "modelpy = modelpytorch(10)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optim = torch.optim.Adam(modelpy.parameters())\n",
        "modelpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wejoH05w66Rr",
        "outputId": "448670e7-ce27-4d94-bd9e-c96bacc53ff0"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "modelpytorch(\n",
              "  (cnn_model): Sequential(\n",
              "    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "    (1): ReLU()\n",
              "    (2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
              "    (3): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
              "    (4): ReLU()\n",
              "    (5): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
              "  )\n",
              "  (fc_model): Sequential(\n",
              "    (0): Linear(in_features=400, out_features=120, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=120, out_features=84, bias=True)\n",
              "    (3): ReLU()\n",
              "  )\n",
              "  (classifier): Linear(in_features=84, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#TensorFlow - Visualizing the Model\n",
        "modeltf.compile(loss=tf.keras.losses.categorical_crossentropy,\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "modeltf.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z4uTQoa472Ri",
        "outputId": "d706f490-1802-4509-939d-14c5cda4752c"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 26, 26, 32)        320       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 13, 13, 32)        0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 11, 11, 64)        18496     \n",
            "                                                                 \n",
            " average_pooling2d (Average  (None, 5, 5, 64)          0         \n",
            " Pooling2D)                                                      \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 1600)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 120)               192120    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 84)                10164     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 10)                850       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 221950 (866.99 KB)\n",
            "Trainable params: 221950 (866.99 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#PyTorch - Training the Model\n",
        "for e in range(30):\n",
        "    # define the loss value after the epoch\n",
        "    losss = 0.0\n",
        "    number_of_sub_epoch = 0\n",
        "\n",
        "    # loop for every training batch (one epoch)\n",
        "    for images, labels in train_loader:\n",
        "        #create the output from the network\n",
        "        out = modelpy(images)\n",
        "        # count the loss function\n",
        "        loss = criterion(out, labels)\n",
        "        # in pytorch you have assign the zero for gradien in any sub epoch\n",
        "        optim.zero_grad()\n",
        "        # count the backpropagation\n",
        "        loss.backward()\n",
        "        # learning\n",
        "        optim.step()\n",
        "        # add new value to the main loss\n",
        "        losss += loss.item()\n",
        "        number_of_sub_epoch += 1\n",
        "    print(\"Epoch {}: Loss: {}\".format(e, losss / number_of_sub_epoch))\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mhZzmAc58Neh",
        "outputId": "54e8d28e-ef39-45f0-cf38-60e4abc59c5c"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0: Loss: 0.6326059960444769\n",
            "Epoch 1: Loss: 0.42425710620482765\n",
            "Epoch 2: Loss: 0.357038085013628\n",
            "Epoch 3: Loss: 0.3171919202884038\n",
            "Epoch 4: Loss: 0.2894999872525533\n",
            "Epoch 5: Loss: 0.26774146287242573\n",
            "Epoch 6: Loss: 0.25056555242737133\n",
            "Epoch 7: Loss: 0.23602735007405282\n",
            "Epoch 8: Loss: 0.222892385567228\n",
            "Epoch 9: Loss: 0.2107965895573298\n",
            "Epoch 10: Loss: 0.20075411873062451\n",
            "Epoch 11: Loss: 0.1920593598783016\n",
            "Epoch 12: Loss: 0.1831951757858197\n",
            "Epoch 13: Loss: 0.17419061341981093\n",
            "Epoch 14: Loss: 0.16690063188423712\n",
            "Epoch 15: Loss: 0.15916002621551353\n",
            "Epoch 16: Loss: 0.1524017849067847\n",
            "Epoch 17: Loss: 0.1461206109777093\n",
            "Epoch 18: Loss: 0.13892268881052733\n",
            "Epoch 19: Loss: 0.13626908117632072\n",
            "Epoch 20: Loss: 0.12947710828098158\n",
            "Epoch 21: Loss: 0.12368368907819191\n",
            "Epoch 22: Loss: 0.12059906367361546\n",
            "Epoch 23: Loss: 0.11574189556154112\n",
            "Epoch 24: Loss: 0.11025754293265443\n",
            "Epoch 25: Loss: 0.10710206641269227\n",
            "Epoch 26: Loss: 0.10644214228553077\n",
            "Epoch 27: Loss: 0.10353749660998583\n",
            "Epoch 28: Loss: 0.09806889307275414\n",
            "Epoch 29: Loss: 0.09461535342031469\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#TensorFlow - Training the Model\n",
        "train_images_tensorflow = (train_images / 255.0).reshape(train_images.shape[0], 28, 28, 1)\n",
        "test_images_tensorflow = (test_images / 255.0).reshape(test_images.shape[0], 28, 28 ,1)\n",
        "train_labels_tensorflow=tf.keras.utils.to_categorical(train_labels)\n",
        "test_labels_tensorflow=tf.keras.utils.to_categorical(test_labels)\n",
        "modeltf.fit(train_images_tensorflow, train_labels_tensorflow, epochs=30, batch_size=32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XExE35c486Nj",
        "outputId": "be42f0c9-731f-4feb-ba0e-b5318046b94f"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "1875/1875 [==============================] - 14s 5ms/step - loss: 0.4912 - accuracy: 0.8178\n",
            "Epoch 2/30\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.3182 - accuracy: 0.8824\n",
            "Epoch 3/30\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2719 - accuracy: 0.9008\n",
            "Epoch 4/30\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2382 - accuracy: 0.9117\n",
            "Epoch 5/30\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2175 - accuracy: 0.9194\n",
            "Epoch 6/30\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1955 - accuracy: 0.9268\n",
            "Epoch 7/30\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1812 - accuracy: 0.9317\n",
            "Epoch 8/30\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1638 - accuracy: 0.9384\n",
            "Epoch 9/30\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1505 - accuracy: 0.9434\n",
            "Epoch 10/30\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1372 - accuracy: 0.9489\n",
            "Epoch 11/30\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1248 - accuracy: 0.9533\n",
            "Epoch 12/30\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1131 - accuracy: 0.9573\n",
            "Epoch 13/30\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1036 - accuracy: 0.9609\n",
            "Epoch 14/30\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0956 - accuracy: 0.9633\n",
            "Epoch 15/30\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0860 - accuracy: 0.9672\n",
            "Epoch 16/30\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0796 - accuracy: 0.9695\n",
            "Epoch 17/30\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0716 - accuracy: 0.9721\n",
            "Epoch 18/30\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0658 - accuracy: 0.9745\n",
            "Epoch 19/30\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0642 - accuracy: 0.9760\n",
            "Epoch 20/30\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0572 - accuracy: 0.9783\n",
            "Epoch 21/30\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0537 - accuracy: 0.9793\n",
            "Epoch 22/30\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0501 - accuracy: 0.9807\n",
            "Epoch 23/30\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0475 - accuracy: 0.9822\n",
            "Epoch 24/30\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0439 - accuracy: 0.9841\n",
            "Epoch 25/30\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0402 - accuracy: 0.9851\n",
            "Epoch 26/30\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0401 - accuracy: 0.9850\n",
            "Epoch 27/30\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0372 - accuracy: 0.9863\n",
            "Epoch 28/30\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0373 - accuracy: 0.9859\n",
            "Epoch 29/30\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0348 - accuracy: 0.9874\n",
            "Epoch 30/30\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0333 - accuracy: 0.9877\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7e95cd466200>"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#PyTorch - Comparing the Results\n",
        "correct = 0\n",
        "total = 0\n",
        "modelpy.eval()\n",
        "for images, labels in test_loader:\n",
        "    outputs = modelpy(images)\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum()\n",
        "print('Test Accuracy of the model on the {} test images: {}% with PyTorch'.format(total, 100 * correct // total))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MMW9m2lfCs6y",
        "outputId": "e5f29372-d701-41ed-8121-7180ce426c9f"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy of the model on the 10000 test images: 89% with PyTorch\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#TensorFlow - Comparing the Results\n",
        "predictions = modeltf.predict(test_images_tensorflow)\n",
        "correct = 0\n",
        "for i, pred in enumerate(predictions):\n",
        "  if np.argmax(pred) == test_labels[i]:\n",
        "    correct += 1\n",
        "print('Test Accuracy of the model on the {} test images: {}% with TensorFlow'.format(test_images.shape[0],\n",
        "                                                                     100 * correct/test_images.shape[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1x70rWHICvXK",
        "outputId": "79b08731-2d00-4c63-8351-8d71f6e4e68e"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 2ms/step\n",
            "Test Accuracy of the model on the 10000 test images: 90.94% with TensorFlow\n"
          ]
        }
      ]
    }
  ]
}